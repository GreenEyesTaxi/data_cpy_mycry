{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сортировка по совпадению документов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Было принято решение обрабатывать файлы по отдельности, так как не во всех файлах существуют документы хоть в каком-нибудь виде.\n",
    "\n",
    "## 1. BoardingData.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerFirstName PassengerSecondName PassengerLastName PassengerSex  \\\n",
      "83246              GORDEI                  M.            GLEBOV         Male   \n",
      "150151              RAMIL         ALBERTOVICH             BUROV         Male   \n",
      "\n",
      "       PassengerBirthDate PassengerDocument    BookingCode      TicketNumber  \\\n",
      "83246          12/31/1982       8248 013778  Not presented  5858732412927507   \n",
      "150151         08/24/1995       8248 013778  Not presented  7230123462656045   \n",
      "\n",
      "           Baggage  FlightDate FlightTime FlightNumber CodeShare Destination  \n",
      "83246   Registered  2017-03-09      07:15       SU1276       Own       Kazan  \n",
      "150151  Registered  2017-01-03      11:15       SU1273       Own      Moscow  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных из CSV файла с указанием разделителя\n",
    "df = pd.read_csv('BoardingData.csv', sep=';')\n",
    "\n",
    "# Удаляем пробелы в названиях столбцов\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "filtered_df = (df.groupby('PassengerDocument')\n",
    "               .filter(lambda x: x['PassengerFirstName'].nunique() > 1 or x['PassengerLastName'].nunique() > 1))\n",
    "\n",
    "# Удаляем дубликаты для удобства\n",
    "final_df = filtered_df.drop_duplicates(subset=['PassengerLastName'])\n",
    "\n",
    "if final_df.empty:\n",
    "    print(\"Совпадений не найдено\")\n",
    "else:\n",
    "    # Выгрузка совпадений в отдельный файл\n",
    "    final_df.to_csv('DuplicatesPassengersCSV.csv', index=False) \n",
    "    print(final_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. JSON. \n",
    "Сначала перевод в CSV для удобства. Файл - FrequentFlyerForum-Profiles.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "with open('./data/Airlines/FrequentFlyerForum-Profiles.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Преобразование данных JSON в pandas DataFrame\n",
    "profiles = data[\"Forum Profiles\"]\n",
    "\n",
    "parsed_data = []\n",
    "for profile in profiles:\n",
    "    first_name = profile[\"Real Name\"][\"First Name\"]\n",
    "    last_name = profile[\"Real Name\"][\"Last Name\"]\n",
    "    sex = profile[\"Sex\"]\n",
    "    document = profile[\"Travel Documents\"][0][\"Passports\"]\n",
    "    \n",
    "    for flight in profile[\"Registered Flights\"]:\n",
    "        if profile.get(\"Loyality Programm\"):\n",
    "            loyality_program = profile[\"Loyality Programm\"][0]\n",
    "            loy_prgrm_status = loyality_program.get(\"Status\", None)\n",
    "            loy_prgrm_code = loyality_program.get(\"programm\", None)\n",
    "            loy_prgrm_number = loyality_program.get(\"Number\", None)\n",
    "        else:\n",
    "            loy_prgrm_status = loy_prgrm_code = loy_prgrm_number = None\n",
    "        \n",
    "        parsed_data.append({\n",
    "            \"First Name\": first_name,\n",
    "            \"Last Name\": last_name,\n",
    "            \"Sex\": sex,\n",
    "            \"Document\": document,\n",
    "            \"Flight Date\": flight[\"Date\"],\n",
    "            \"Flight Number\": flight[\"Flight\"],\n",
    "            \"Share Code\": flight[\"Codeshare\"],\n",
    "            \"ArrivalCity\": flight[\"Arrival\"][\"City\"],\n",
    "            \"ArrivalAirport\": flight[\"Arrival\"][\"Airport\"], \n",
    "            \"DepartureCity\": flight[\"Departure\"][\"City\"],   \n",
    "            \"DepartureAirport\": flight[\"Departure\"][\"Airport\"],\n",
    "            \"NickName\": profile.get(\"NickName\", None), \n",
    "            \"LoyPrgrmStatus\": loy_prgrm_status,\n",
    "            \"LoyPrgrmCode\": loy_prgrm_code,\n",
    "            \"LoyPrgrmNumber\": loy_prgrm_number\n",
    "        })\n",
    "\n",
    "# Преобразование списка в pandas DataFrame\n",
    "df_json = pd.DataFrame(parsed_data)\n",
    "df_json.to_csv('FrequentFlyerForum-Profiles-json.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Совпадений не найдено\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных из CSV файла с указанием разделителя\n",
    "df = pd.read_csv('FrequentFlyerForum-Profiles-json.csv', sep=',')\n",
    "\n",
    "# Удаляем пробелы в названиях столбцов\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "filtered_df = (df.groupby('Document')\n",
    "               .filter(lambda x: x['First Name'].nunique() > 1 or x['Last Name'].nunique() > 1))\n",
    "\n",
    "# Удаляем дубликаты для удобства\n",
    "final_df = filtered_df.drop_duplicates()\n",
    "\n",
    "if final_df.empty:\n",
    "    print(\"Совпадений не найдено\")\n",
    "else:\n",
    "    \n",
    "    # Выгрузка совпадений в отдельный файл\n",
    "    final_df.to_csv('DuplicatesPassengersJSON.csv', index=False) \n",
    "    \n",
    "    # Выводим итоговый DataFrame\n",
    "    print(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sirena-export-fixed.tab. \n",
    "Схема та же, что и с JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "colspecs = [\n",
    "    (0, 60),   # PaxName\n",
    "    (60, 72),  # PaxBirthDate\n",
    "    (72, 84),  # DepartDate\n",
    "    (84, 96),  # DepartTime\n",
    "    (96, 108),  # ArrivalDate\n",
    "    (108, 120),  # ArrivalTime\n",
    "    (120, 126),  # Flight\n",
    "    (126, 132),  # CodeSh\n",
    "    (132, 138),  # From\n",
    "    (138, 144),  # Dest\n",
    "    (144, 150),  # Code\n",
    "    (150, 168),  # e-Ticket\n",
    "    (168, 180), # TravelDoc\n",
    "    (180, 186),# Seat\n",
    "    (186, 192),# Meal\n",
    "    (192, 198),# TrvCls\n",
    "    (198, 216),# Fare  Baggage\n",
    "    (216, 240),# PaxAdditionalInfo\n",
    "    (240, 246),# Unnamed: 18\n",
    "    (246, 276), # Unnamed: 19\n",
    "    (276, 336) # AgentInfo\n",
    "]\n",
    "\n",
    "df_tab = pd.read_fwf('./data/Airlines/Sirena-export-fixed.tab', colspecs=colspecs, dtype={'Unnamed: 19': 'str', 'Unnamed: 18': 'str'})\n",
    "\n",
    "# Удаляем 'FF#' в столбце Unnamed: 18, оставляем только программный код (например, 'DT')\n",
    "df_tab['Unnamed: 18'] = df_tab['Unnamed: 18'].str.replace('FF#', '', regex=False)\n",
    "\n",
    "# Шаг 4: Разделение PaxName на три части (Last Name, First Name, Second Name)\n",
    "#df_tab[['Last Name', 'First Name', 'Second Name']] = df_tab['PaxName'].str.split(expand=True, n=2)\n",
    "\n",
    "# Шаг 5: Переименование и объединение столбцов из Sirena с основным датасетом\n",
    "df_tab = df_tab.rename(columns={\n",
    "    'PaxBirthDate': 'Birth Date',\n",
    "    'Flight': 'Flight Number',\n",
    "    'CodeSh': 'Share Code',\n",
    "    'From': 'DepartureAirport',\n",
    "    'Dest': 'ArrivalAirport',\n",
    "    'Code': 'BookingCode',\n",
    "    'e-Ticket': 'TicketNumber',\n",
    "    'TravelDoc': 'Document',\n",
    "    'Fare  Baggage': 'Baggage',\n",
    "    'DepartDate': 'Flight Date',\n",
    "    'DepartTime': 'FlightTime',\n",
    "    'Unnamed: 19': 'LoyPrgrmNumber',\n",
    "    'Unnamed: 18': 'LoyPrgrmCode'\n",
    "})\n",
    "\n",
    "df_tab.to_csv('Sirena-export-fixed-tab.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaxName</th>\n",
       "      <th>Birth Date</th>\n",
       "      <th>Flight Date</th>\n",
       "      <th>FlightTime</th>\n",
       "      <th>ArrivalDate</th>\n",
       "      <th>ArrivalTime</th>\n",
       "      <th>Flight Number</th>\n",
       "      <th>Share Code</th>\n",
       "      <th>DepartureAirport</th>\n",
       "      <th>ArrivalAirport</th>\n",
       "      <th>...</th>\n",
       "      <th>TicketNumber</th>\n",
       "      <th>Document</th>\n",
       "      <th>Seat</th>\n",
       "      <th>Meal</th>\n",
       "      <th>TrvCls</th>\n",
       "      <th>Baggage</th>\n",
       "      <th>PaxAdditionalInfo</th>\n",
       "      <th>LoyPrgrmCode</th>\n",
       "      <th>LoyPrgrmNumber</th>\n",
       "      <th>AgentInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ОЗЕРОВ ИЛЬДАР ДАНИИЛОВИЧ</td>\n",
       "      <td>1999-05-15</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>00:05</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>08:05</td>\n",
       "      <td>SU1306</td>\n",
       "      <td>NO</td>\n",
       "      <td>SVO</td>\n",
       "      <td>OVB</td>\n",
       "      <td>...</td>\n",
       "      <td>7360415302044672</td>\n",
       "      <td>9375 053270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "      <td>JGRPGN0PC</td>\n",
       "      <td>S</td>\n",
       "      <td>SU</td>\n",
       "      <td>38116280</td>\n",
       "      <td>Go2See</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>КОЛОСОВ САМИР ТАМЕРЛАНОВИЧ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>02:15</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>04:40</td>\n",
       "      <td>SU1323</td>\n",
       "      <td>NO</td>\n",
       "      <td>MMK</td>\n",
       "      <td>SVO</td>\n",
       "      <td>...</td>\n",
       "      <td>7398421117936516</td>\n",
       "      <td>2244 645520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KSML</td>\n",
       "      <td>Y</td>\n",
       "      <td>YRSTUQ</td>\n",
       "      <td>9</td>\n",
       "      <td>FB</td>\n",
       "      <td>284903754</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ИГНАТОВА СНЕЖАНА КОНСТАНТИНОВНА</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09-19</td>\n",
       "      <td>06:40</td>\n",
       "      <td>2017-09-19</td>\n",
       "      <td>07:45</td>\n",
       "      <td>SU1481</td>\n",
       "      <td>NO</td>\n",
       "      <td>KJA</td>\n",
       "      <td>SVO</td>\n",
       "      <td>...</td>\n",
       "      <td>5174973140468001</td>\n",
       "      <td>8115 961316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>YSTNJL</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KupiBilet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ЖАРОВ ПЛАТОН АЛЬБЕРТОВИЧ</td>\n",
       "      <td>1999-05-02</td>\n",
       "      <td>2017-03-18</td>\n",
       "      <td>22:10</td>\n",
       "      <td>2017-03-19</td>\n",
       "      <td>01:05</td>\n",
       "      <td>SU1180</td>\n",
       "      <td>NO</td>\n",
       "      <td>SVO</td>\n",
       "      <td>VOG</td>\n",
       "      <td>...</td>\n",
       "      <td>5274206497242737</td>\n",
       "      <td>98 6865148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "      <td>JFLXLS0PC</td>\n",
       "      <td>#</td>\n",
       "      <td>FB</td>\n",
       "      <td>884556993</td>\n",
       "      <td>Travelgenio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>НИКОЛЬСКИЙ НИКОЛАЙ ИГОРЕВИЧ</td>\n",
       "      <td>1990-12-26</td>\n",
       "      <td>2017-03-18</td>\n",
       "      <td>22:10</td>\n",
       "      <td>2017-03-19</td>\n",
       "      <td>01:05</td>\n",
       "      <td>SU1180</td>\n",
       "      <td>NO</td>\n",
       "      <td>SVO</td>\n",
       "      <td>VOG</td>\n",
       "      <td>...</td>\n",
       "      <td>6247422701565929</td>\n",
       "      <td>4396 926588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>YFLXPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SU</td>\n",
       "      <td>183142068</td>\n",
       "      <td>OZON.travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ГЛУШКОВ КОНСТАНТИН ИЛЬИЧ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>11:45</td>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>12:25</td>\n",
       "      <td>SU6284</td>\n",
       "      <td>NO</td>\n",
       "      <td>UUS</td>\n",
       "      <td>SVO</td>\n",
       "      <td>...</td>\n",
       "      <td>5874178506968181</td>\n",
       "      <td>4788 422492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>YGRPPN0PC</td>\n",
       "      <td>8</td>\n",
       "      <td>FB</td>\n",
       "      <td>553284496</td>\n",
       "      <td>KupiBilet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>КАПУСТИН АРТЁМ ЭДУАРДОВИЧ</td>\n",
       "      <td>1982-10-24</td>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>11:45</td>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>12:25</td>\n",
       "      <td>SU6284</td>\n",
       "      <td>NO</td>\n",
       "      <td>UUS</td>\n",
       "      <td>SVO</td>\n",
       "      <td>...</td>\n",
       "      <td>7467749130398378</td>\n",
       "      <td>0058 142289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VLML</td>\n",
       "      <td>Y</td>\n",
       "      <td>YFLXNM2PC</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KupiBilet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ЕРШОВА ЛЮБОВЬ ЗАХАРОВНА</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>11:45</td>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>12:25</td>\n",
       "      <td>SU6284</td>\n",
       "      <td>NO</td>\n",
       "      <td>UUS</td>\n",
       "      <td>SVO</td>\n",
       "      <td>...</td>\n",
       "      <td>2183161939566868</td>\n",
       "      <td>0776 380126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>YGRPYX0PC</td>\n",
       "      <td>#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aeroflot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ТИТОВА ЗАРИНА ЭМИЛЬЕВНА</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>14:15</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>15:45</td>\n",
       "      <td>SU1281</td>\n",
       "      <td>NO</td>\n",
       "      <td>KZN</td>\n",
       "      <td>SVO</td>\n",
       "      <td>...</td>\n",
       "      <td>5954073786122008</td>\n",
       "      <td>53 7554162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>YSTNXJ1PC</td>\n",
       "      <td>8</td>\n",
       "      <td>FB</td>\n",
       "      <td>933538031</td>\n",
       "      <td>OZON.travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>БАРСУКОВ САМИР ГОРДЕЕВИЧ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>14:15</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>15:45</td>\n",
       "      <td>SU1281</td>\n",
       "      <td>NO</td>\n",
       "      <td>KZN</td>\n",
       "      <td>SVO</td>\n",
       "      <td>...</td>\n",
       "      <td>2264717979478322</td>\n",
       "      <td>0078 271703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>YGRPPP1PC</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aeroflot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           PaxName  Birth Date Flight Date FlightTime  \\\n",
       "0         ОЗЕРОВ ИЛЬДАР ДАНИИЛОВИЧ  1999-05-15  2017-05-30      00:05   \n",
       "1       КОЛОСОВ САМИР ТАМЕРЛАНОВИЧ         NaN  2017-12-27      02:15   \n",
       "2  ИГНАТОВА СНЕЖАНА КОНСТАНТИНОВНА         NaN  2017-09-19      06:40   \n",
       "3         ЖАРОВ ПЛАТОН АЛЬБЕРТОВИЧ  1999-05-02  2017-03-18      22:10   \n",
       "4      НИКОЛЬСКИЙ НИКОЛАЙ ИГОРЕВИЧ  1990-12-26  2017-03-18      22:10   \n",
       "5         ГЛУШКОВ КОНСТАНТИН ИЛЬИЧ         NaN  2017-03-12      11:45   \n",
       "6        КАПУСТИН АРТЁМ ЭДУАРДОВИЧ  1982-10-24  2017-03-12      11:45   \n",
       "7          ЕРШОВА ЛЮБОВЬ ЗАХАРОВНА         NaN  2017-03-12      11:45   \n",
       "8          ТИТОВА ЗАРИНА ЭМИЛЬЕВНА         NaN  2017-07-29      14:15   \n",
       "9         БАРСУКОВ САМИР ГОРДЕЕВИЧ         NaN  2017-07-29      14:15   \n",
       "\n",
       "  ArrivalDate ArrivalTime Flight Number Share Code DepartureAirport  \\\n",
       "0  2017-05-30       08:05        SU1306         NO              SVO   \n",
       "1  2017-12-27       04:40        SU1323         NO              MMK   \n",
       "2  2017-09-19       07:45        SU1481         NO              KJA   \n",
       "3  2017-03-19       01:05        SU1180         NO              SVO   \n",
       "4  2017-03-19       01:05        SU1180         NO              SVO   \n",
       "5  2017-03-12       12:25        SU6284         NO              UUS   \n",
       "6  2017-03-12       12:25        SU6284         NO              UUS   \n",
       "7  2017-03-12       12:25        SU6284         NO              UUS   \n",
       "8  2017-07-29       15:45        SU1281         NO              KZN   \n",
       "9  2017-07-29       15:45        SU1281         NO              KZN   \n",
       "\n",
       "  ArrivalAirport  ...      TicketNumber     Document Seat  Meal TrvCls  \\\n",
       "0            OVB  ...  7360415302044672  9375 053270  NaN   NaN      J   \n",
       "1            SVO  ...  7398421117936516  2244 645520  NaN  KSML      Y   \n",
       "2            SVO  ...  5174973140468001  8115 961316  NaN   NaN      Y   \n",
       "3            VOG  ...  5274206497242737   98 6865148  NaN   NaN      J   \n",
       "4            VOG  ...  6247422701565929  4396 926588  NaN   NaN      Y   \n",
       "5            SVO  ...  5874178506968181  4788 422492  NaN   NaN      Y   \n",
       "6            SVO  ...  7467749130398378  0058 142289  NaN  VLML      Y   \n",
       "7            SVO  ...  2183161939566868  0776 380126  NaN   NaN      Y   \n",
       "8            SVO  ...  5954073786122008   53 7554162  NaN   NaN      Y   \n",
       "9            SVO  ...  2264717979478322  0078 271703  NaN   NaN      Y   \n",
       "\n",
       "     Baggage PaxAdditionalInfo LoyPrgrmCode LoyPrgrmNumber    AgentInfo  \n",
       "0  JGRPGN0PC                 S           SU       38116280       Go2See  \n",
       "1     YRSTUQ                 9           FB      284903754          NaN  \n",
       "2     YSTNJL                 F          NaN            NaN    KupiBilet  \n",
       "3  JFLXLS0PC                 #           FB      884556993  Travelgenio  \n",
       "4     YFLXPG               NaN           SU      183142068  OZON.travel  \n",
       "5  YGRPPN0PC                 8           FB      553284496    KupiBilet  \n",
       "6  YFLXNM2PC                 F          NaN            NaN    KupiBilet  \n",
       "7  YGRPYX0PC                 #          NaN            NaN     Aeroflot  \n",
       "8  YSTNXJ1PC                 8           FB      933538031  OZON.travel  \n",
       "9  YGRPPP1PC                 F          NaN            NaN     Aeroflot  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tab.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         PaxName  Birth Date Flight Date FlightTime  \\\n",
      "93152    ГЛЕБОВ ГОРДЕЙ МАКАРЕВИЧ  1982-12-31  2017-01-16      01:45   \n",
      "150692  БУРОВ РАМИЛЬ АЛЬБЕРТОВИЧ  1995-08-24  2017-01-03      11:15   \n",
      "\n",
      "       ArrivalDate ArrivalTime Flight Number Share Code DepartureAirport  \\\n",
      "93152   2017-01-16       04:35        SU1057         NO              MCX   \n",
      "150692  2017-01-03       13:35        SU1273         NO              KRR   \n",
      "\n",
      "       ArrivalAirport  ...      TicketNumber     Document Seat  Meal TrvCls  \\\n",
      "93152             SVO  ...  2082229451418171  8248 013778  NaN  KSML      Y   \n",
      "150692            SVO  ...  7230123462656045  8248 013778  NaN   NaN      A   \n",
      "\n",
      "       Baggage PaxAdditionalInfo LoyPrgrmCode LoyPrgrmNumber  AgentInfo  \n",
      "93152   YGRPFD                 F          NaN            NaN    trip.ru  \n",
      "150692  ASTNLM               NaN          NaN            NaN        NaN  \n",
      "\n",
      "[2 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных из CSV файла с указанием разделителя\n",
    "df = pd.read_csv('Sirena-export-fixed-tab.csv', sep=',')\n",
    "\n",
    "# Удаляем пробелы в названиях столбцов\n",
    "#df.columns = df.columns.str.strip()\n",
    "\n",
    "filtered_df = (df.groupby('Document')\n",
    "               .filter(lambda x: x['PaxName'].nunique() > 1))\n",
    "\n",
    "# Удаляем дубликаты для удобства\n",
    "final_df = filtered_df.drop_duplicates()\n",
    "\n",
    "if final_df.empty:\n",
    "    print(\"Совпадений не найдено\")\n",
    "else:\n",
    "    \n",
    "    # Выгрузка совпадений в отдельный файл\n",
    "    final_df.to_csv('DuplicatesPassengersTAB.csv', index=False) \n",
    "    \n",
    "    # Выводим итоговый DataFrame\n",
    "    print(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. XLSX. \n",
    "В отдельном ноутбуке было сведение и перевод в CSV формат всех таблиц. В этом файле нет колонки с документами, поэтому происходит сравнение на билет. (ну пусть будет) (пока что получается хрень)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Совпадений не найдено\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных из CSV файла с указанием разделителя\n",
    "df = pd.read_csv('xlsx_data.csv', sep=',')\n",
    "\n",
    "# Удаляем пробелы в названиях столбцов\n",
    "#df.columns = df.columns.str.strip()\n",
    "\n",
    "filtered_df = (df.groupby('TicketNumber')\n",
    "               .filter(lambda x: x['Full Name'].nunique() > 1))\n",
    "\n",
    "# Удаляем дубликаты для удобства\n",
    "final_df = filtered_df.drop_duplicates(subset=['Full Name'])\n",
    "\n",
    "if final_df.empty:\n",
    "    print(\"Совпадений не найдено\")\n",
    "else:\n",
    "    \n",
    "    # Выгрузка совпадений в отдельный файл\n",
    "    final_df.to_csv('DuplicatesPassengersXLSX.csv', index=False) \n",
    "    \n",
    "    # Выводим итоговый DataFrame\n",
    "    print(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('./data/Airlines/PointzAggregator-AirlinesData.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Создаем список для хранения данных\n",
    "data = []\n",
    "\n",
    "# Проходим по каждому пользователю\n",
    "for user in root.findall('user'):\n",
    "    uid = user.get('uid')  # ID пользователя\n",
    "    first_name = user.find('name').get('first')  # Имя пользователя\n",
    "    last_name = user.find('name').get('last')  # Фамилия пользователя\n",
    "    \n",
    "    # Проходим по каждой карточке\n",
    "    for card in user.findall('cards/card'):\n",
    "        card_number = card.get('number')  # Номер карты\n",
    "        bonus_program = card.find('bonusprogramm').text  # Бонусная программа\n",
    "        \n",
    "        # Проходим по каждой активности (рейсу)\n",
    "        for activity in card.findall('activities/activity'):\n",
    "            flight_code = activity.find('Code').text  # Код рейса\n",
    "            flight_date = activity.find('Date').text  # Дата рейса\n",
    "            departure = activity.find('Departure').text  # Место вылета\n",
    "            arrival = activity.find('Arrival').text  # Место прилета\n",
    "            fare = activity.find('Fare').text  # Тип тарифа\n",
    "            \n",
    "            # Добавляем все данные в список\n",
    "            data.append({\n",
    "                'User uid': uid,\n",
    "                'First Name': first_name,\n",
    "                'Last Name': last_name,\n",
    "                'CardNumber': card_number,\n",
    "                'BonusProgram': bonus_program,\n",
    "                'Flight Number': flight_code,\n",
    "                'Flight Date': flight_date,\n",
    "                'DepartureAirport': departure,\n",
    "                'ArrivalAirport': arrival\n",
    "            })\n",
    "\n",
    "# Преобразуем список в DataFrame\n",
    "df_xml = pd.DataFrame(data)\n",
    "df_xml.to_csv('PointzAggregator-AirlinesData-xml.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User uid</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>CardNumber</th>\n",
       "      <th>BonusProgram</th>\n",
       "      <th>Flight Number</th>\n",
       "      <th>Flight Date</th>\n",
       "      <th>DepartureAirport</th>\n",
       "      <th>ArrivalAirport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>613142142</td>\n",
       "      <td>IAROMIR</td>\n",
       "      <td>ZVEREV</td>\n",
       "      <td>FB 171388778</td>\n",
       "      <td>Flying Blue</td>\n",
       "      <td>KE827</td>\n",
       "      <td>2017-08-06</td>\n",
       "      <td>rea</td>\n",
       "      <td>SZX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>613142142</td>\n",
       "      <td>IAROMIR</td>\n",
       "      <td>ZVEREV</td>\n",
       "      <td>FB 171388778</td>\n",
       "      <td>Flying Blue</td>\n",
       "      <td>MU9706</td>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>PEK</td>\n",
       "      <td>BSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103197717</td>\n",
       "      <td>VITALINA</td>\n",
       "      <td>KOROVINA</td>\n",
       "      <td>KE 696768759</td>\n",
       "      <td>Korean Air SKYPASS</td>\n",
       "      <td>DL5058</td>\n",
       "      <td>2017-09-11</td>\n",
       "      <td>CHA</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103197717</td>\n",
       "      <td>VITALINA</td>\n",
       "      <td>KOROVINA</td>\n",
       "      <td>KE 696768759</td>\n",
       "      <td>Korean Air SKYPASS</td>\n",
       "      <td>KE1</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>rea</td>\n",
       "      <td>HNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103197717</td>\n",
       "      <td>VITALINA</td>\n",
       "      <td>KOROVINA</td>\n",
       "      <td>KE 696768759</td>\n",
       "      <td>Korean Air SKYPASS</td>\n",
       "      <td>DL837</td>\n",
       "      <td>2017-09-13</td>\n",
       "      <td>ATL</td>\n",
       "      <td>HNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>103197717</td>\n",
       "      <td>VITALINA</td>\n",
       "      <td>KOROVINA</td>\n",
       "      <td>KE 696768759</td>\n",
       "      <td>Korean Air SKYPASS</td>\n",
       "      <td>SU1523</td>\n",
       "      <td>2017-02-12</td>\n",
       "      <td>NUX</td>\n",
       "      <td>SVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>138879468</td>\n",
       "      <td>DANIL</td>\n",
       "      <td>VAVILOV</td>\n",
       "      <td>DT 980250352</td>\n",
       "      <td>Delta SkyMiles</td>\n",
       "      <td>AF4445</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>AJA</td>\n",
       "      <td>ORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>138879468</td>\n",
       "      <td>DANIL</td>\n",
       "      <td>VAVILOV</td>\n",
       "      <td>DT 980250352</td>\n",
       "      <td>Delta SkyMiles</td>\n",
       "      <td>AZ7545</td>\n",
       "      <td>2017-03-07</td>\n",
       "      <td>FCO</td>\n",
       "      <td>PRG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>138879468</td>\n",
       "      <td>DANIL</td>\n",
       "      <td>VAVILOV</td>\n",
       "      <td>DT 980250352</td>\n",
       "      <td>Delta SkyMiles</td>\n",
       "      <td>AF7331</td>\n",
       "      <td>2017-09-17</td>\n",
       "      <td>MLH</td>\n",
       "      <td>ORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>138879468</td>\n",
       "      <td>DANIL</td>\n",
       "      <td>VAVILOV</td>\n",
       "      <td>DT 980250352</td>\n",
       "      <td>Delta SkyMiles</td>\n",
       "      <td>AF4102</td>\n",
       "      <td>2017-10-07</td>\n",
       "      <td>ORY</td>\n",
       "      <td>AJA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User uid First Name Last Name    CardNumber        BonusProgram  \\\n",
       "0  613142142    IAROMIR    ZVEREV  FB 171388778         Flying Blue   \n",
       "1  613142142    IAROMIR    ZVEREV  FB 171388778         Flying Blue   \n",
       "2  103197717   VITALINA  KOROVINA  KE 696768759  Korean Air SKYPASS   \n",
       "3  103197717   VITALINA  KOROVINA  KE 696768759  Korean Air SKYPASS   \n",
       "4  103197717   VITALINA  KOROVINA  KE 696768759  Korean Air SKYPASS   \n",
       "5  103197717   VITALINA  KOROVINA  KE 696768759  Korean Air SKYPASS   \n",
       "6  138879468      DANIL   VAVILOV  DT 980250352      Delta SkyMiles   \n",
       "7  138879468      DANIL   VAVILOV  DT 980250352      Delta SkyMiles   \n",
       "8  138879468      DANIL   VAVILOV  DT 980250352      Delta SkyMiles   \n",
       "9  138879468      DANIL   VAVILOV  DT 980250352      Delta SkyMiles   \n",
       "\n",
       "  Flight Number Flight Date DepartureAirport ArrivalAirport  \n",
       "0         KE827  2017-08-06              rea            SZX  \n",
       "1        MU9706  2017-10-26              PEK            BSD  \n",
       "2        DL5058  2017-09-11              CHA            ATL  \n",
       "3           KE1  2017-04-01              rea            HNL  \n",
       "4         DL837  2017-09-13              ATL            HNL  \n",
       "5        SU1523  2017-02-12              NUX            SVO  \n",
       "6        AF4445  2017-11-11              AJA            ORY  \n",
       "7        AZ7545  2017-03-07              FCO            PRG  \n",
       "8        AF7331  2017-09-17              MLH            ORY  \n",
       "9        AF4102  2017-10-07              ORY            AJA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xml.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         User uid First Name    Last Name    CardNumber BonusProgram  \\\n",
      "130045  146589094      ROMAN  MASLENNIKOV  FB 139888197  Flying Blue   \n",
      "312850  866799462     OLESYA     GOLOVINA  FB 139888197  Flying Blue   \n",
      "\n",
      "       Flight Number Flight Date DepartureAirport ArrivalAirport  \n",
      "130045        MU5529  2017-08-17              SHA            DQA  \n",
      "312850        ME2231  2017-07-29              BEY            FCO  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных из CSV файла с указанием разделителя\n",
    "df = pd.read_csv('PointzAggregator-AirlinesData-xml.csv', sep=',')\n",
    "\n",
    "# Удаляем пробелы в названиях столбцов\n",
    "#df.columns = df.columns.str.strip()\n",
    "\n",
    "filtered_df = (df.groupby('CardNumber')\n",
    "               .filter(lambda x: x['First Name'].nunique() > 1 or x['Last Name'].nunique() > 1))\n",
    "\n",
    "# Удаляем дубликаты для удобства\n",
    "final_df = filtered_df.drop_duplicates(subset=['Last Name', 'First Name'])\n",
    "\n",
    "if final_df.empty:\n",
    "    print(\"Совпадений не найдено\")\n",
    "else:\n",
    "    \n",
    "    # Выгрузка совпадений в отдельный файл\n",
    "    final_df.to_csv('DuplicatesPassengersXML.csv', index=False) \n",
    "    \n",
    "    # Выводим итоговый DataFrame\n",
    "    print(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение карты\n",
    "После выявления наиболее и наименее посещаемых городов, которые были даны списком, нужно было разместить их на карту."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Находим координаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_coordinates_opencage(city, api_key):\n",
    "    url = f\"https://api.opencagedata.com/geocode/v1/json?q={city}&key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data['results']:\n",
    "            location = data['results'][0]['geometry']\n",
    "            return (location['lng'], location['lat'])\n",
    "        else:\n",
    "            print(f\"Координаты для {city} не найдены.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Ошибка при получении координат для {city}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Ваш API-ключ OpenCage\n",
    "api_key = '378915dab2e24376b44d14d2a49bb97d'  # Замените на ваш API-ключ\n",
    "\n",
    "# Список городов\n",
    "cities = [\n",
    "    \"rio cuarto\",\n",
    "    \"providenciales\",\n",
    "    \"sintang\",\n",
    "    \"cozumel\",\n",
    "    \"kingston\",\n",
    "    \"santa rosa\",\n",
    "    \"regina\",\n",
    "    \"cartagena\",\n",
    "    \"medellin\",\n",
    "    \"roatan\",\n",
    "    \"moscow\",\n",
    "    \"paris\",\n",
    "    \"atlanta ga\",\n",
    "    \"new york ny\",\n",
    "    \"amsterdam\",\n",
    "    \"shanghai\",\n",
    "    \"rome\",\n",
    "    \"seoul\",\n",
    "    \"detroit mi\",\n",
    "    \"minneapolis\"\n",
    "]\n",
    "\n",
    "# Получение координат для каждого города\n",
    "coordinates = {}\n",
    "for city in cities:\n",
    "    coords = get_coordinates_opencage(city, api_key)\n",
    "    if coords:\n",
    "        coordinates[city] = coords\n",
    "\n",
    "# Вывод результатов\n",
    "for city, coord in coordinates.items():\n",
    "    print(f\"{city}, {coord[0]}, {coord[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Создание карты и сохранение в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Загрузка данных из CSV файлов\n",
    "most_visited = pd.read_csv('./data/cities_most.csv')\n",
    "least_visited = pd.read_csv('./data/cities_list.csv')\n",
    "\n",
    "# Создание карты\n",
    "plt.figure(figsize=(15, 10))  # Увеличение размера изображения\n",
    "map = Basemap(projection='merc', lat_0=0, lon_0=0, resolution='i')  # Используем 'i' для более высокой детализации\n",
    "\n",
    "# Нанесение сетки на карту\n",
    "map.drawmapboundary(fill_color='#46bcec')\n",
    "map.fillcontinents(color='#f2f2f2', lake_color='#46bcec')\n",
    "map.drawcoastlines()\n",
    "map.drawcountries()   # Добавление границ стран для большей точности\n",
    "\n",
    "# Добавление точек для наиболее посещаемых городов (синий цвет)\n",
    "lon_most = most_visited['lon'].values\n",
    "lat_most = most_visited['lat'].values\n",
    "x_most, y_most = map(lon_most, lat_most)\n",
    "map.scatter(x_most, y_most, 30, marker='o', color='blue', zorder=5)\n",
    "\n",
    "# Добавление точек для наименее посещаемых городов (красный цвет)\n",
    "lon_least = least_visited['lon'].values\n",
    "lat_least = least_visited['lat'].values\n",
    "x_least, y_least = map(lon_least, lat_least)\n",
    "map.scatter(x_least, y_least, 30, marker='o', color='red', zorder=5)\n",
    "\n",
    "# Убираем подписи координат\n",
    "map.drawparallels([])  # Убираем параллели\n",
    "map.drawmeridians([])  # Убираем меридианы\n",
    "\n",
    "# Добавление легенды\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Сохранение карты в файл\n",
    "plt.savefig('combined_cities_map.png', bbox_inches='tight', dpi=1200)  # Увеличение разрешения изображения\n",
    "\n",
    "print(\"Карта успешно создана и сохранена в файл 'combined_cities_map.png'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
